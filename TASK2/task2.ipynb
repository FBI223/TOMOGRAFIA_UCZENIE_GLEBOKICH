{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/FBI223/TOMOGRAFIA_UCZENIE_GLEBOKICH/blob/main/TASK2/task2.ipynb)\n"
   ],
   "id": "5fcd81bb57c2fbf8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Zadanie obowiazkowe : Odpalenie modelu i wizualizacja dzialania modelu\n",
    "\n",
    "W tej czƒô≈õci student samodzielnie **u≈ºyje gotowego, wytrenowanego modelu U-Net** do przeprowadzenia **segmentacji tomografii komputerowej p≈Çuc (CT)**.\n",
    "\n",
    "Celem jest:\n",
    "\n",
    "1. Wczytanie modelu z pliku `.ckpt`,\n",
    "2. Wczytanie danych 3D konkretnego pacjenta (`.nii.gz`),\n",
    "3. Przeprowadzenie predykcji maski nowotworu dla ka≈ºdej warstwy CT,\n",
    "4. Stworzenie animacji pokazujƒÖcej segmentacjƒô,\n",
    "\n",
    "Podpowiedz : Uzyj funkcji\n"
   ],
   "id": "596702e59d6c6e20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from onedrivedownloader import download\n",
    "url = \"https://ujchmura-my.sharepoint.com/:u:/g/personal/marcin_sztukowski_student_uj_edu_pl/EeIxSRDsbaROj51n9jl7TDoBTifXVohnxCVymwhyiGrBSQ?e=IRznML\"\n",
    "download(url, filename=\"epoch=29-step=53759.ckpt\", unzip=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML, Video\n",
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import os\n",
    "\n",
    "\n",
    "def load_trained_model(checkpoint_path, model_class = TumorSegmentation, device=None):\n",
    "    \"\"\"\n",
    "    Wczytuje wytrenowany model PyTorch Lightning z pliku .ckpt\n",
    "\n",
    "    Args:\n",
    "        checkpoint_path: ≈õcie≈ºka do pliku checkpoint (.ckpt)\n",
    "        model_class: klasa modelu (np. TumorSegmentation)\n",
    "        device: 'cuda', 'cpu' lub None (automatycznie wykrywane)\n",
    "\n",
    "    Returns:\n",
    "        model: za≈Çadowany i gotowy do ewaluacji model\n",
    "    \"\"\"\n",
    "\n",
    "    # automatyczne wykrycie urzƒÖdzenia\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # wczytanie modelu z checkpointu\n",
    "    print(f\"üîÑ Loading model from: {checkpoint_path}\")\n",
    "    model = model_class.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # przeniesienie na GPU/CPU\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_video(scan, segmentation, save_path=\"/content/ct_tumor_animation.mp4\",\n",
    "                              step=2, fps=10):\n",
    "    \"\"\"\n",
    "    Tworzy wideo MP4 z segmentacji CT bez u≈ºycia matplotlib.animation (dzia≈Ça w Colabie bez b≈Çƒôd√≥w).\n",
    "    \"\"\"\n",
    "    os.makedirs(\"/content/tmp_frames\", exist_ok=True)\n",
    "    tmp_dir = \"/content/tmp_frames\"\n",
    "\n",
    "    # --- zapis pojedynczych klatek ---\n",
    "    for idx, i in enumerate(tqdm(range(0, len(scan), step), desc=\"Rendering frames\")):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(scan[i], cmap=\"bone\")\n",
    "        mask = np.ma.masked_where(segmentation[i] == 0, segmentation[i])\n",
    "        plt.imshow(mask, alpha=0.5, cmap=\"autumn\")\n",
    "        plt.axis(\"off\")\n",
    "        frame_path = f\"{tmp_dir}/frame_{idx:04d}.png\"\n",
    "        plt.savefig(frame_path, bbox_inches=\"tight\", pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "    # --- sk≈Çadanie filmu przez ffmpeg ---\n",
    "    print(\"üíæ Rendering wideo przez ffmpeg...\")\n",
    "    cmd = f\"ffmpeg -y -framerate {fps} -i {tmp_dir}/frame_%04d.png -c:v libx264 -pix_fmt yuv420p {save_path}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "    # --- czyszczenie ---\n",
    "    for f in os.listdir(tmp_dir):\n",
    "        os.remove(os.path.join(tmp_dir, f))\n",
    "    os.rmdir(tmp_dir)\n",
    "\n",
    "    print(f\"‚úÖ Zapisano: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_single_patient(model, ct_volume, device=\"cuda\", threshold=0.5):\n",
    "    \"\"\"\n",
    "    Segmentacja jednego pacjenta (CT volume) przy u≈ºyciu modelu (np. U-Net).\n",
    "\n",
    "    Args:\n",
    "        model: wytrenowany model PyTorch (np. U-Net)\n",
    "        ct_volume: numpy array 3D (H, W, N) ‚Äî pe≈Çny tomogram pacjenta\n",
    "        device: 'cuda' lub 'cpu'\n",
    "        threshold: pr√≥g binarny dla maski (np. 0.5)\n",
    "\n",
    "    Returns:\n",
    "        scan: lista 2D obraz√≥w (oryginalnych slice'√≥w)\n",
    "        segmentation: lista 2D masek binarnych\n",
    "        preds: lista masek z warto≈õciami sigmoid (float)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    scan = []\n",
    "    segmentation = []\n",
    "    preds = []\n",
    "\n",
    "    for i in tqdm(range(ct_volume.shape[-1])):\n",
    "        # --- przygotowanie slice‚Äôa ---\n",
    "        slice_ = cv2.resize(ct_volume[:, :, i], (256, 256))\n",
    "        scan.append(slice_)\n",
    "\n",
    "        input_t = torch.tensor(slice_).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # --- predykcja modelu ---\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(input_t))[0, 0].cpu().numpy()\n",
    "\n",
    "        preds.append(pred)\n",
    "        segmentation.append((pred > threshold).astype(np.uint8))\n",
    "\n",
    "    scan = np.array(scan)\n",
    "    segmentation = np.array(segmentation)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    return scan, segmentation, preds\n",
    "\n",
    "\n"
   ],
   "id": "434b1e9e4700fc56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# üë©‚Äçüéì CZƒò≈öƒÜ STUDENTA\n",
    "# ======================================================\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from IPython.display import Video\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "MAX_VAL = 3071\n",
    "CROP_SIZE = 30\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#stale do stworzenia wideo\n",
    "STEPS = 2\n",
    "FPS=10\n",
    "\n",
    "\n",
    "# wczytaj pobrany model / checkpoint\n",
    "checkpoint = \"/content/POBRANY_MODEL...\" # TODO\n",
    "model = load_trained_model( ) #TODO\n",
    "subject = Path(\"/content/Task06_Lung/imagesTs/DANE_PACJENTA.nii.gz\") #TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Uzyj nib.load oraz get_fdata aby wczytac dane dowolnego pacjenta\n",
    "# pamietaj aby podzielic przez MAX_VAL wczytane dane aby ustandaryzowac dane\n",
    "# pamietaj aby zrobic CROP wczytanych danych\n",
    "\n",
    "subject = Path(\"/content/Task06_Lung/imagesTs/WYBIERZ_ZDJECIE\") #TODO\n",
    "ct = nib.load  #TODO load\n",
    "ct = ct[...]  # TODO crop\n",
    "scan, segmentation, preds =  ...  #TODO uzyj funkcji wyzej\n",
    "\n",
    "#uzyj gotowej funkcji do stworzenia video z klatek   #TODO\n",
    "Video(\"/content/VIDEO.mp4\", embed=True) #TODO\n",
    "\n",
    "\n"
   ],
   "id": "11e74f92b31e24f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# üë®‚Äçüè´ CZƒò≈öƒÜ NAUCZYCIELA\n",
    "# ======================================================\n",
    "\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "MAX_VAL = 3071\n",
    "CROP_SIZE = 30\n",
    "#stale do stworzenia wideo\n",
    "STEPS = 2\n",
    "FPS=10\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint = \"/content/epoch=29-step=53759.ckpt\"\n",
    "model = load_trained_model(checkpoint_path=checkpoint, model_class=TumorSegmentation)\n",
    "subject = Path(\"/content/Task06_Lung/imagesTs/lung_035.nii.gz\")\n",
    "ct = nib.load(subject).get_fdata() / MAX_VAL  # standardize\n",
    "ct = ct[:,:,CROP_SIZE:]  # crop\n",
    "scan, segmentation, preds = predict_single_patient(model, ct, device=DEVICE)\n",
    "create_segmentation_video(scan, segmentation, \"/content/ct_tumor_animation_35.mp4\", step=STEPS, fps=FPS)\n",
    "Video(\"/content/ct_tumor_animation_35.mp4\", embed=True)\n",
    "\n",
    "\n"
   ],
   "id": "ac0347bf3bfe9315"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
